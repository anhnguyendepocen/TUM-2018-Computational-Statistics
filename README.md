Syllabus - Computational Statistics Summer Semester 2019

Lecture 1: Basic random number generation

    Generation of random variables from select discrete and continuous distributions
    Inverse transform method
    Acceptance-rejection algorithm
    Sample quantiles


Lecture 2: Complex distribution simulation

    Transformations
    Convolutions
    Mixtures
    Multivariate normal distribution
    Matrix decomposition
    Wishart distribution


Lecture 3: Monte Carlo integration

    Monte Carlo integration
    MC standard errors and confidence intervals
    Variance reduction by antithetic and control variates
    Importance sampling
    Stratified sampling


Lecture 4: Bootstrap

    Resampling and empirical cdf
    Bootstrap scheme
    Bootstrap standard error
    Bootstrap bias
    Bootstrap CI
    Parametric bootstrap, also called MC inference
    Design of experiments


Lecture 5: Permutation tests

    Permutation distribution
    Exact and approximate permutation tests
    Jackknife
    Cross-validation


Lecture 6: MCMC

    Frequentist inference
    Bayesian inference
    Markov chains
    Metropolis-Hastings algorithm
    Metropolis sampler
    Random walk metropolis
    Independence sampler
    Gibbs sampler


Lecture 7: Numerical methods

    Computer representations
    Taylor series
    Root-finding
    Numerical integration
    Optimization
    Maximum likelihood
    EM Algorithm


Lecture 8: Statistical learning

    Terminology, motivating examples
    Supervised learning methods
    Classification
    Loss functions and expected prediction error
    Additive error models
    Penalty functions


Lecture 9: Association rules

    Association rules, market basket analysis
    Apriori algorithm
    Terminology, including support, confidence and lift
    Generalized association rule mining, including bump hunting

Literature
    Rizzo, M.L. (2008): Statistical Computing with R, Chapman & Hall/CRC (available via eAccess (second edition, 2019))
    Abraham, B. and Ledolter, J. (2006): Introduction to Regression Modeling, Thomson/Brooks Cole.
    Hastie, T.; Tibshirani, R. and Friedman, J. (2009): The Elements of Statistical Learning, Springer. (available online)

The course use R: Tidyverse by installing the package tidyverse. This package is actually a collection of packages and we will make use of some of them, like ggplot2, readr or dplyr.
